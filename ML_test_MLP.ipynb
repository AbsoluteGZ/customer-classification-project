{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c5b7c8",
   "metadata": {},
   "source": [
    "# ============Необходимые библиотеки и фреймворки============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c791b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d73cc",
   "metadata": {},
   "source": [
    "# ================0. КОНФИГУРАЦИЯ MLFLOW================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01bec95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Experiment: Customer_Class_NN_Aggregated\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"ML test task v3\")\n",
    "ARTIFACTS_PATH = Path(\"saved_models\")\n",
    "ARTIFACTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# Настройка MLflow\n",
    "mlflow.set_experiment(\"Customer_Class_NN_Aggregate\")\n",
    "print(f\"MLflow Experiment: {mlflow.get_experiment_by_name('Customer_Class_NN_Aggregated').name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92b282",
   "metadata": {},
   "source": [
    "# ================1. ЗАГРУЗКА И ПОДГОТОВКА ДАННЫХ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e340c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. Загрузка и подготовка данных ---\n",
      "Распределение классов после агрегации:\n",
      " cus_class_agg\n",
      "0    0.709510\n",
      "1    0.270753\n",
      "2    0.019737\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 1. Загрузка и подготовка данных ---\")\n",
    "\n",
    "# --- Загрузка исходных данных ---\n",
    "macro_df = pd.read_csv(DATA_PATH / \"context_df.csv\")\n",
    "contracts_df = pd.read_parquet(DATA_PATH / \"test_task.parquet\")\n",
    "\n",
    "# --- Предобработка макроэкономической таблицы ---\n",
    "macro_df.columns = macro_df.columns.str.lower().str.replace(' ', '_')\n",
    "macro_df['context_data_from'] = pd.to_datetime(macro_df['context_data_from'])\n",
    "percent_cols = ['inflation', 'key_rate', 'deposit_1', 'deposit_3', 'deposit_6', 'deposit_12', 'fa_delta', 'usd_delta', 'imoex_delta', 'rgbi_delta']\n",
    "for col in percent_cols:\n",
    "    macro_df[col] = pd.to_numeric(macro_df[col].str.replace('%', ''), errors='coerce')\n",
    "\n",
    "macro_df.ffill(inplace=True)\n",
    "macro_df.bfill(inplace=True)\n",
    "\n",
    "# --- Предобработка таблицы контрактов ---\n",
    "contracts_df.rename(columns={'Договор Дата Заключения': 'contract_date'}, inplace=True)\n",
    "contracts_df['cus_class'] = contracts_df['cus_class'].astype(int)\n",
    "\n",
    "# --- Объединение таблиц по дате ---\n",
    "merged_df = pd.merge_asof(\n",
    "    contracts_df.sort_values('contract_date'),\n",
    "    macro_df.sort_values('context_data_from'),\n",
    "    left_on='contract_date',\n",
    "    right_on='context_data_from',\n",
    "    direction='backward'\n",
    ").dropna(subset=macro_df.columns)\n",
    "\n",
    "# --- Создание временных признаков ---\n",
    "merged_df['day_of_year'] = merged_df['contract_date'].dt.dayofyear\n",
    "merged_df['day_of_week'] = merged_df['contract_date'].dt.dayofweek\n",
    "merged_df['month'] = merged_df['contract_date'].dt.month\n",
    "\n",
    "# --- Агрегация классов в 3 группы ---\n",
    "def aggregate_cus_class(c):\n",
    "    if c in [1, 5, 8, 10, 4]: return 0  # Группа 'Base'\n",
    "    if c in [101, 102, 103, 104, 105, 106, 107, 108, 109]: return 1  # Группа 'Premium'\n",
    "    return 2  # Группа 'Rare'\n",
    "\n",
    "merged_df['cus_class_agg'] = merged_df['cus_class'].apply(aggregate_cus_class)\n",
    "print(\"Распределение классов после агрегации:\\n\", merged_df['cus_class_agg'].value_counts(normalize=True))\n",
    "\n",
    "# --- Финальное формирование X и y ---\n",
    "features = [\n",
    "    'quarter', 'inflation', 'key_rate', 'deposit_1', 'deposit_3', 'deposit_6',\n",
    "    'deposit_12', 'fa_delta', 'usd_delta', 'imoex_delta', 'rgbi_delta',\n",
    "    'day_of_year', 'day_of_week', 'month'\n",
    "]\n",
    "X = merged_df[features]\n",
    "y = merged_df['cus_class_agg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2438c",
   "metadata": {},
   "source": [
    "# ===========2. ПОДГОТОВКА ВЫБОРКИ ДЛЯ ОБУЧЕНИЯ============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9d3ef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Подготовка выборок для обучения ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 2. Подготовка выборок для обучения ---\")\n",
    "\n",
    "# --- Разделение на обучающую и тестовую выборки ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# --- Масштабирование признаков ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Преобразование в тензоры PyTorch ---\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# --- Создание DataLoader'ов ---\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307893c",
   "metadata": {},
   "source": [
    "# =========3. ПОДГОТОВКА МОДЕЛИ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27e4a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"Простая полносвязная нейронная сеть для классификации.\"\"\"\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_features, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# --- Параметры обучения ---\n",
    "N_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_FEATURES = X_train.shape[1]\n",
    "NUM_CLASSES = len(y.unique())\n",
    "class_names = ['Base', 'Premium', 'Rare']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Расчет весов для борьбы с дисбалансом классов ---\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float32)\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "# --- Инициализация модели и компонентов для обучения ---\n",
    "model = Classifier(num_features=NUM_FEATURES, num_classes=NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c670d70",
   "metadata": {},
   "source": [
    "# =========4. ВСПОМОГАТЕЛЬНАЯ ФУНКЦИЯ ДЛЯ ОЦЕНКИ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "631cecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_log_pytorch(model, data_loader, device, class_names):\n",
    "    \"\"\"Оценивает модель, выводит метрики, логирует их и матрицу ошибок в MLflow.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs.to(device))\n",
    "            all_preds.extend(torch.max(outputs, 1)[1].cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(\"\\n--- Финальная оценка модели ---\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names, zero_division=0))\n",
    "\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "    mlflow.log_metric(\"final_test_f1_macro\", f1_macro)\n",
    "    \n",
    "    # --- Матрица ошибок ---\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    cm_path = \"confusion_matrix.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    plt.close()\n",
    "    print(f\"Матрица ошибок сохранена и залогирована в MLflow как '{cm_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e13686",
   "metadata": {},
   "source": [
    "# =========5. ЗАПУСК ОБУЧЕНИЯ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2ad3cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. Запуск обучения на устройстве: cpu ---\n",
      "Эпоха [10/100], Validation Loss: 0.9451\n",
      "Эпоха [20/100], Validation Loss: 0.9491\n",
      "Эпоха [30/100], Validation Loss: 0.9462\n",
      "Эпоха [40/100], Validation Loss: 0.9493\n",
      "Эпоха [50/100], Validation Loss: 0.9471\n",
      "Эпоха [60/100], Validation Loss: 0.9520\n",
      "Эпоха [70/100], Validation Loss: 0.9449\n",
      "Эпоха [80/100], Validation Loss: 0.9510\n",
      "Эпоха [90/100], Validation Loss: 0.9524\n",
      "Эпоха [100/100], Validation Loss: 0.9532\n",
      "\n",
      "--- Финальная оценка модели ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Base       0.84      0.75      0.79      2934\n",
      "     Premium       0.57      0.49      0.53      1119\n",
      "        Rare       0.07      0.49      0.12        82\n",
      "\n",
      "    accuracy                           0.67      4135\n",
      "   macro avg       0.49      0.57      0.48      4135\n",
      "weighted avg       0.75      0.67      0.70      4135\n",
      "\n",
      "Матрица ошибок сохранена и залогирована в MLflow как 'confusion_matrix.png'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/29 16:36:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/29 16:36:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение завершено. Модель и артефакты сохранены в MLflow.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- 5. Запуск обучения на устройстве: {device} ---\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_params({\"epochs\": N_EPOCHS, \"learning_rate\": LEARNING_RATE, \"batch_size\": BATCH_SIZE})\n",
    "    \n",
    "    for epoch in range(N_EPOCHS):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Валидация в процессе обучения\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs.to(device))\n",
    "                val_loss += criterion(outputs, labels.to(device)).item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(test_loader)\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Эпоха [{epoch+1}/{N_EPOCHS}], Validation Loss: {avg_val_loss:.4f}\")\n",
    "        mlflow.log_metric(\"validation_loss\", avg_val_loss, step=epoch)\n",
    "\n",
    "    # --- Финальная оценка и сохранение артефактов ---\n",
    "    evaluate_and_log_pytorch(model, test_loader, device, class_names)\n",
    "    \n",
    "    with open(ARTIFACTS_PATH / \"scaler.pkl\", \"wb\") as f: pickle.dump(scaler, f)\n",
    "    class_mapping = {i: name for i, name in enumerate(class_names)}\n",
    "    with open(ARTIFACTS_PATH / \"class_mapping.json\", \"w\") as f: json.dump(class_mapping, f)\n",
    "\n",
    "    mlflow.pytorch.log_model(model, \"model_pytorch\")\n",
    "    mlflow.log_artifact(str(ARTIFACTS_PATH / \"scaler.pkl\"))\n",
    "    mlflow.log_artifact(str(ARTIFACTS_PATH / \"class_mapping.json\"))\n",
    "    \n",
    "    print(\"\\nОбучение завершено. Модель и артефакты сохранены в MLflow.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
