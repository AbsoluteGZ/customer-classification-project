{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959bf2e7",
   "metadata": {},
   "source": [
    "# ============Необходимые библиотеки и фреймворки============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47827f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import mlflow\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631eb4e6",
   "metadata": {},
   "source": [
    "# ================0. КОНФИГУРАЦИЯ MLFLOW================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "771cd9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/29 16:31:55 INFO mlflow.tracking.fluent: Experiment with name 'Customer_Class_Tree_Model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: file:./mlruns\n",
      "MLflow Experiment: Customer_Class_Tree_Models\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "mlflow.set_experiment(\"Customer_Class_Tree_Model\")\n",
    "print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"MLflow Experiment: Customer_Class_Tree_Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c8987c",
   "metadata": {},
   "source": [
    "# ================1. ЗАГРУЗКА И ПОДГОТОВКА ДАННЫХ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba6375ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Загрузка данных...\n",
      "Предобработка данных и создание признаков...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nЗагрузка данных...\")\n",
    "macro_df = pd.read_csv('ML test task v3/context_df.csv')\n",
    "contracts_df = pd.read_parquet('ML test task v3/test_task.parquet')\n",
    "\n",
    "print(\"Предобработка данных и создание признаков...\")\n",
    "\n",
    "# --- Обработка макроэкономических данных ---\n",
    "macro_df['context_data_from'] = pd.to_datetime(macro_df['context_data_from'])\n",
    "macro_df['context_data_to'] = pd.to_datetime(macro_df['context_data_to'])\n",
    "\n",
    "def clean_and_convert_numeric(series):\n",
    "    return pd.to_numeric(\n",
    "        series.astype(str).str.replace('%', '', regex=False).str.replace(',', '.', regex=False),\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "numeric_macro_features = [\n",
    "    'inflation', 'key_rate', 'deposit_1', 'deposit_3', 'deposit_6', 'deposit_12',\n",
    "    'fa_delta', 'usd_delta', 'IMOEX_delta', 'RGBI_delta'\n",
    "]\n",
    "\n",
    "for col in numeric_macro_features:\n",
    "    macro_df[col] = clean_and_convert_numeric(macro_df[col])\n",
    "macro_df.dropna(subset=numeric_macro_features, inplace=True)\n",
    "\n",
    "# --- Создание лагов и дельт для макро-признаков ---\n",
    "macro_df_for_merge = macro_df.rename(columns={'context_data_from': 'quarter_start_date'}).sort_values('quarter_start_date')\n",
    "engineered_macro_features = numeric_macro_features.copy()\n",
    "\n",
    "for feature in numeric_macro_features:\n",
    "    for lag in [1, 2]:\n",
    "        lag_feature_name = f'{feature}_lag{lag}'\n",
    "        macro_df_for_merge[lag_feature_name] = macro_df_for_merge[feature].shift(lag)\n",
    "        engineered_macro_features.append(lag_feature_name)\n",
    "    \n",
    "    delta_feature_name = f'{feature}_delta1'\n",
    "    macro_df_for_merge[delta_feature_name] = macro_df_for_merge[feature] - macro_df_for_merge[f'{feature}_lag1']\n",
    "    engineered_macro_features.append(delta_feature_name)\n",
    "\n",
    "# --- Обработка данных о контрактах ---\n",
    "date_col = 'Договор Дата Заключения'\n",
    "contracts_df[date_col] = pd.to_datetime(contracts_df[date_col])\n",
    "contracts_df['quarter_start_date'] = contracts_df[date_col].dt.to_period('Q').dt.start_time\n",
    "\n",
    "# --- Создание временных признаков ---\n",
    "contracts_df['contract_year'] = contracts_df[date_col].dt.year\n",
    "contracts_df['contract_quarter'] = contracts_df[date_col].dt.quarter\n",
    "contracts_df['contract_month'] = contracts_df[date_col].dt.month\n",
    "contracts_df['contract_dayofweek'] = contracts_df[date_col].dt.dayofweek\n",
    "categorical_date_features = ['contract_year', 'contract_quarter', 'contract_month', 'contract_dayofweek']\n",
    "\n",
    "# --- Объединение датасетов ---\n",
    "merged_df = pd.merge(contracts_df, macro_df_for_merge, on='quarter_start_date', how='left')\n",
    "all_features_for_model = engineered_macro_features + categorical_date_features\n",
    "merged_df.dropna(subset=all_features_for_model + ['cus_class'], inplace=True)\n",
    "\n",
    "# --- Кодирование целевой переменной ---\n",
    "label_encoder = LabelEncoder()\n",
    "merged_df['cus_class_encoded'] = label_encoder.fit_transform(merged_df['cus_class'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de5b11a",
   "metadata": {},
   "source": [
    "# ===========2. ПОДГОТОВКА ВЫБОРКИ ДЛЯ ОБУЧЕНИЯ============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76c121c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подготовка выборок и балансировка...\n",
      "Размер обучающей выборки после балансировки: (9000, 44)\n",
      "Распределение классов в обучающей выборке: [(0, 500), (1, 500), (2, 500), (3, 500), (4, 500), (5, 500), (6, 500), (7, 500), (8, 500), (9, 500), (10, 500), (11, 500), (12, 500), (13, 500), (14, 500), (15, 500), (16, 500), (17, 500)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Подготовка выборок и балансировка...\")\n",
    "X = merged_df[all_features_for_model]\n",
    "y = merged_df['cus_class_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Балансировка обучающей выборки ---\n",
    "target_samples_per_class = 500\n",
    "ros = RandomOverSampler(\n",
    "    sampling_strategy={cls: max(cnt, target_samples_per_class) for cls, cnt in Counter(y_train).items()},\n",
    "    random_state=42\n",
    ")\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "rus = RandomUnderSampler(\n",
    "    sampling_strategy={cls: target_samples_per_class for cls in Counter(y_resampled).keys()},\n",
    "    random_state=42\n",
    ")\n",
    "X_train_final, y_train_final = rus.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "print(f\"Размер обучающей выборки после балансировки: {X_train_final.shape}\")\n",
    "print(f\"Распределение классов в обучающей выборке: {sorted(Counter(y_train_final).items())}\")\n",
    "\n",
    "cat_features_indices = [X_train_final.columns.get_loc(col) for col in categorical_date_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410f8d3",
   "metadata": {},
   "source": [
    "# =========3. ВСПОМОГАТЕЛЬНАЯ ФУНКЦИЯ ДЛЯ ОЦЕНКИ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38005466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. ВСПОМОГАТЕЛЬНАЯ ФУНКЦИЯ ДЛЯ ОЦЕНКИ\n",
    "# ==============================================================================\n",
    "\n",
    "def evaluate_and_log(model, X_test, y_test, model_name, class_names):\n",
    "    \"\"\"Оценивает модель, выводит метрики, логирует их в MLflow и сохраняет матрицу ошибок.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Расчет метрик\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n--- Результаты для {model_name} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    # Логирование метрик в MLflow\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"test_f1_macro\", f1_macro)\n",
    "    mlflow.log_metric(\"test_balanced_accuracy\", balanced_acc)\n",
    "\n",
    "    # Создание и логирование матрицы ошибок\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    cm_path = f\"confusion_matrix_{model_name.lower()}.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc9ab6",
   "metadata": {},
   "source": [
    "# ==================4. ОБУЧЕНИЕ МОДЕЛЕЙ======================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893dcb7",
   "metadata": {},
   "source": [
    "# ----------------- Блок LightGBM -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42b8ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Обучение LightGBM ---\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1196\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Info] Start training from score -2.890372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "--- Результаты для LightGBM ---\n",
      "Accuracy: 0.2771\n",
      "F1-score (Macro): 0.1711\n",
      "Balanced Accuracy: 0.2896\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.44      0.24      0.31       478\n",
      "         2.0       0.03      0.33      0.05        12\n",
      "         4.0       0.51      0.04      0.07       708\n",
      "         5.0       0.60      0.20      0.30      1093\n",
      "         6.0       0.09      0.77      0.16        31\n",
      "         7.0       0.07      0.69      0.13        29\n",
      "         8.0       0.08      0.06      0.07        69\n",
      "        10.0       0.61      0.86      0.72       533\n",
      "       100.0       0.01      0.25      0.02         8\n",
      "       101.0       0.07      0.08      0.07        76\n",
      "       102.0       0.06      0.14      0.09       105\n",
      "       103.0       0.38      0.38      0.38       197\n",
      "       104.0       0.01      0.09      0.02        23\n",
      "       105.0       0.19      0.23      0.20       110\n",
      "       106.0       0.30      0.19      0.24       324\n",
      "       107.0       0.08      0.14      0.10        57\n",
      "       108.0       0.07      0.47      0.12        43\n",
      "       109.0       0.02      0.05      0.03        38\n",
      "\n",
      "    accuracy                           0.28      3934\n",
      "   macro avg       0.20      0.29      0.17      3934\n",
      "weighted avg       0.45      0.28      0.29      3934\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/29 16:31:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/29 16:32:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Обучение LightGBM ---\")\n",
    "with mlflow.start_run(run_name=\"LightGBM\"):\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    \n",
    "    lgbm_params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': num_classes,\n",
    "        'metric': 'multi_logloss',\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.03,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': -1,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "    }\n",
    "    mlflow.log_params(lgbm_params)\n",
    "    \n",
    "    model_lgb = lgb.LGBMClassifier(**lgbm_params)\n",
    "    model_lgb.fit(\n",
    "        X_train_final, y_train_final,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric='multi_logloss',\n",
    "        callbacks=[lgb.early_stopping(50, verbose=False)],\n",
    "        categorical_feature=cat_features_indices\n",
    "    )\n",
    "    \n",
    "    evaluate_and_log(model_lgb, X_test, y_test, \"LightGBM\", class_names)\n",
    "    mlflow.lightgbm.log_model(model_lgb, \"model\")\n",
    "    joblib.dump(label_encoder, \"label_encoder.joblib\")\n",
    "    mlflow.log_artifact(\"label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2caaa2",
   "metadata": {},
   "source": [
    "# ----------------- Блок XGBoost -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94368fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Обучение XGBoost ---\n",
      "\n",
      "--- Результаты для XGBoost ---\n",
      "Accuracy: 0.2443\n",
      "F1-score (Macro): 0.1614\n",
      "Balanced Accuracy: 0.2643\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.43      0.28      0.34       478\n",
      "         2.0       0.03      0.33      0.05        12\n",
      "         4.0       0.50      0.11      0.18       708\n",
      "         5.0       0.59      0.11      0.18      1093\n",
      "         6.0       0.10      0.74      0.18        31\n",
      "         7.0       0.05      0.45      0.09        29\n",
      "         8.0       0.05      0.09      0.06        69\n",
      "        10.0       0.66      0.72      0.69       533\n",
      "       100.0       0.01      0.25      0.02         8\n",
      "       101.0       0.04      0.08      0.05        76\n",
      "       102.0       0.05      0.10      0.07       105\n",
      "       103.0       0.32      0.30      0.31       197\n",
      "       104.0       0.02      0.13      0.03        23\n",
      "       105.0       0.18      0.25      0.21       110\n",
      "       106.0       0.26      0.18      0.21       324\n",
      "       107.0       0.09      0.16      0.11        57\n",
      "       108.0       0.06      0.44      0.10        43\n",
      "       109.0       0.01      0.03      0.01        38\n",
      "\n",
      "    accuracy                           0.24      3934\n",
      "   macro avg       0.19      0.26      0.16      3934\n",
      "weighted avg       0.44      0.24      0.27      3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Обучение XGBoost ---\")\n",
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    \n",
    "    # Для XGBoost категориальные признаки должны быть типа 'category'\n",
    "    X_train_xgb = X_train_final.copy()\n",
    "    X_test_xgb = X_test.copy()\n",
    "    for col in categorical_date_features:\n",
    "        X_train_xgb[col] = X_train_xgb[col].astype(\"category\")\n",
    "        X_test_xgb[col] = X_test_xgb[col].astype(\"category\")\n",
    "    \n",
    "    xgb_params = {\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': num_classes,\n",
    "        'n_estimators': 300,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 7,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'seed': 42,\n",
    "        'enable_categorical': True, # Важный параметр для работы с типом 'category'\n",
    "    }\n",
    "    mlflow.log_params(xgb_params)\n",
    "\n",
    "    model_xgb = xgb.XGBClassifier(**xgb_params)\n",
    "    model_xgb.fit(X_train_xgb, y_train_final)\n",
    "    \n",
    "    evaluate_and_log(model_xgb, X_test_xgb, y_test, \"XGBoost\", class_names)\n",
    "    model_path = \"xgb_model.json\"\n",
    "    model_xgb.save_model(model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "    joblib.dump(label_encoder, \"label_encoder.joblib\")\n",
    "    mlflow.log_artifact(\"label_encoder.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb00e3",
   "metadata": {},
   "source": [
    "# ----------------- Блок CatBoost -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61eaeda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Обучение CatBoost ---\n",
      "\n",
      "--- Результаты для CatBoost ---\n",
      "Accuracy: 0.2661\n",
      "F1-score (Macro): 0.1684\n",
      "Balanced Accuracy: 0.2743\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.47      0.22      0.30       478\n",
      "         2.0       0.03      0.33      0.06        12\n",
      "         4.0       0.53      0.08      0.15       708\n",
      "         5.0       0.58      0.17      0.26      1093\n",
      "         6.0       0.08      0.65      0.14        31\n",
      "         7.0       0.05      0.45      0.09        29\n",
      "         8.0       0.06      0.06      0.06        69\n",
      "        10.0       0.62      0.82      0.71       533\n",
      "       100.0       0.01      0.25      0.02         8\n",
      "       101.0       0.03      0.04      0.03        76\n",
      "       102.0       0.06      0.12      0.08       105\n",
      "       103.0       0.38      0.40      0.39       197\n",
      "       104.0       0.02      0.13      0.04        23\n",
      "       105.0       0.19      0.28      0.23       110\n",
      "       106.0       0.26      0.18      0.21       324\n",
      "       107.0       0.09      0.19      0.12        57\n",
      "       108.0       0.07      0.47      0.12        43\n",
      "       109.0       0.02      0.11      0.03        38\n",
      "\n",
      "    accuracy                           0.27      3934\n",
      "   macro avg       0.20      0.27      0.17      3934\n",
      "weighted avg       0.45      0.27      0.28      3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Обучение CatBoost ---\")\n",
    "with mlflow.start_run(run_name=\"CatBoost\"):\n",
    "    mlflow.log_param(\"model_type\", \"CatBoost\")\n",
    "\n",
    "    catboost_params = {\n",
    "        'iterations': 500,\n",
    "        'learning_rate': 0.05,\n",
    "        'depth': 8,\n",
    "        'loss_function': 'MultiClass',\n",
    "        'verbose': 0, # Отключаем вывод во время обучения\n",
    "        'random_seed': 42\n",
    "    }\n",
    "    mlflow.log_params(catboost_params)\n",
    "\n",
    "    model_cb = cb.CatBoostClassifier(**catboost_params)\n",
    "    model_cb.fit(\n",
    "        X_train_final, y_train_final,\n",
    "        cat_features=cat_features_indices,\n",
    "        eval_set=(X_test, y_test),\n",
    "        early_stopping_rounds=50,\n",
    "    )\n",
    "    \n",
    "    evaluate_and_log(model_cb, X_test, y_test, \"CatBoost\", class_names)\n",
    "    model_path = \"catboost_model.cbm\"\n",
    "    model_cb.save_model(model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "    joblib.dump(label_encoder, \"label_encoder.joblib\")\n",
    "    mlflow.log_artifact(\"label_encoder.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
